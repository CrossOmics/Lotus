# Auto-generated by scripts/generate_scanpy_proxies.py
from __future__ import annotations

import inspect

import scanpy.external.tl as _orig_module

__all__ = [
    "cyclone",
    "harmony_timeseries",
    "palantir",
    "palantir_results",
    "phate",
    "phenograph",
    "sam",
    "sandbag",
    "trimap",
    "wishbone"
]

def cyclone(adata: 'AnnData' = None, marker_pairs: 'Mapping[str, Collection[tuple[str, str]]] | None' = None, *, iterations: 'int' = 1000, min_iter: 'int' = 100, min_pairs: 'int' = 50, **_lotus_extras) -> 'pd.DataFrame':
    _lotus_kwargs = {}
    if iterations != 1000:
        _lotus_kwargs['iterations'] = iterations
    if min_iter != 100:
        _lotus_kwargs['min_iter'] = min_iter
    if min_pairs != 50:
        _lotus_kwargs['min_pairs'] = min_pairs
    _lotus_call_args = []
    if adata is not None:
        _lotus_call_args.append(adata)
    _lotus_call_args.append(marker_pairs)
    return _orig_module.cyclone(*_lotus_call_args, **_lotus_kwargs, **_lotus_extras)

def harmony_timeseries(adata: 'AnnData', tp: 'str', *, n_neighbors: 'int' = 30, n_components: 'int | None' = 1000, n_jobs: 'int' = -2, copy: 'bool' = False, **_lotus_extras) -> 'AnnData | None':
    _lotus_kwargs = {}
    if n_neighbors != 30:
        _lotus_kwargs['n_neighbors'] = n_neighbors
    if n_components != 1000:
        _lotus_kwargs['n_components'] = n_components
    if n_jobs != -2:
        _lotus_kwargs['n_jobs'] = n_jobs
    if copy != False:
        _lotus_kwargs['copy'] = copy
    _lotus_call_args = []
    _lotus_call_args.append(adata)
    _lotus_call_args.append(tp)
    return _orig_module.harmony_timeseries(*_lotus_call_args, **_lotus_kwargs, **_lotus_extras)

def palantir(adata: 'AnnData' = None, *, n_components: 'int' = 10, knn: 'int' = 30, alpha: 'float' = 0, use_adjacency_matrix: 'bool' = False, distances_key: 'str | None' = None, n_eigs: 'int | None' = None, impute_data: 'bool' = True, n_steps: 'int' = 3, copy: 'bool' = False, **_lotus_extras) -> 'AnnData | None':
    _lotus_kwargs = {}
    if n_components != 10:
        _lotus_kwargs['n_components'] = n_components
    if knn != 30:
        _lotus_kwargs['knn'] = knn
    if alpha != 0:
        _lotus_kwargs['alpha'] = alpha
    if use_adjacency_matrix != False:
        _lotus_kwargs['use_adjacency_matrix'] = use_adjacency_matrix
    if distances_key is not None:
        _lotus_kwargs['distances_key'] = distances_key
    if n_eigs is not None:
        _lotus_kwargs['n_eigs'] = n_eigs
    if impute_data != True:
        _lotus_kwargs['impute_data'] = impute_data
    if n_steps != 3:
        _lotus_kwargs['n_steps'] = n_steps
    if copy != False:
        _lotus_kwargs['copy'] = copy
    _lotus_call_args = []
    if adata is not None:
        _lotus_call_args.append(adata)
    return _orig_module.palantir(*_lotus_call_args, **_lotus_kwargs, **_lotus_extras)

def palantir_results(adata: 'AnnData', early_cell: 'str', *, ms_data: 'str' = 'X_palantir_multiscale', terminal_states: 'list | None' = None, knn: 'int' = 30, num_waypoints: 'int' = 1200, n_jobs: 'int' = -1, scale_components: 'bool' = True, use_early_cell_as_start: 'bool' = False, max_iterations: 'int' = 25, **_lotus_extras) -> 'AnnData | None':
    _lotus_kwargs = {}
    if ms_data != 'X_palantir_multiscale':
        _lotus_kwargs['ms_data'] = ms_data
    if terminal_states is not None:
        _lotus_kwargs['terminal_states'] = terminal_states
    if knn != 30:
        _lotus_kwargs['knn'] = knn
    if num_waypoints != 1200:
        _lotus_kwargs['num_waypoints'] = num_waypoints
    if n_jobs != -1:
        _lotus_kwargs['n_jobs'] = n_jobs
    if scale_components != True:
        _lotus_kwargs['scale_components'] = scale_components
    if use_early_cell_as_start != False:
        _lotus_kwargs['use_early_cell_as_start'] = use_early_cell_as_start
    if max_iterations != 25:
        _lotus_kwargs['max_iterations'] = max_iterations
    _lotus_call_args = []
    _lotus_call_args.append(adata)
    _lotus_call_args.append(early_cell)
    return _orig_module.palantir_results(*_lotus_call_args, **_lotus_kwargs, **_lotus_extras)

def phate(adata: 'AnnData', n_components: 'int' = 2, *, k: 'int' = 5, a: 'int' = 15, n_landmark: 'int' = 2000, t: 'int | str' = 'auto', gamma: 'float' = 1.0, n_pca: 'int' = 100, knn_dist: 'str' = 'euclidean', mds_dist: 'str' = 'euclidean', mds: "Literal['classic', 'metric', 'nonmetric']" = 'metric', n_jobs: 'int | None' = None, random_state: '_LegacyRandom' = None, verbose: 'bool | int | None' = None, copy: 'bool' = False, **kwargs) -> 'AnnData | None':
    _lotus_kwargs = {}
    if k != 5:
        _lotus_kwargs['k'] = k
    if a != 15:
        _lotus_kwargs['a'] = a
    if n_landmark != 2000:
        _lotus_kwargs['n_landmark'] = n_landmark
    if t != 'auto':
        _lotus_kwargs['t'] = t
    if gamma != 1.0:
        _lotus_kwargs['gamma'] = gamma
    if n_pca != 100:
        _lotus_kwargs['n_pca'] = n_pca
    if knn_dist != 'euclidean':
        _lotus_kwargs['knn_dist'] = knn_dist
    if mds_dist != 'euclidean':
        _lotus_kwargs['mds_dist'] = mds_dist
    if mds != 'metric':
        _lotus_kwargs['mds'] = mds
    if n_jobs is not None:
        _lotus_kwargs['n_jobs'] = n_jobs
    if random_state is not None:
        _lotus_kwargs['random_state'] = random_state
    if verbose is not None:
        _lotus_kwargs['verbose'] = verbose
    if copy != False:
        _lotus_kwargs['copy'] = copy
    _lotus_kwargs.update(kwargs)
    return _orig_module.phate(adata, n_components, **_lotus_kwargs)

def phenograph(data: 'AnnData | np.ndarray | SpBase', clustering_algo: "Literal['louvain', 'leiden'] | None" = 'louvain', *, k: 'int' = 30, directed: 'bool' = False, prune: 'bool' = False, min_cluster_size: 'int' = 10, jaccard: 'bool' = True, primary_metric: "Literal['euclidean', 'manhattan', 'correlation', 'cosine']" = 'euclidean', n_jobs: 'int' = -1, q_tol: 'float' = 0.001, louvain_time_limit: 'int' = 2000, nn_method: "Literal['kdtree', 'brute']" = 'kdtree', partition_type: 'type[MutableVertexPartition] | None' = None, resolution_parameter: 'float' = 1, n_iterations: 'int' = -1, use_weights: 'bool' = True, seed: 'int | None' = None, copy: 'bool' = False, **kargs: 'Any') -> 'tuple[np.ndarray | None, SpBase, float | None] | None':
    _lotus_kwargs = {}
    if k != 30:
        _lotus_kwargs['k'] = k
    if directed != False:
        _lotus_kwargs['directed'] = directed
    if prune != False:
        _lotus_kwargs['prune'] = prune
    if min_cluster_size != 10:
        _lotus_kwargs['min_cluster_size'] = min_cluster_size
    if jaccard != True:
        _lotus_kwargs['jaccard'] = jaccard
    if primary_metric != 'euclidean':
        _lotus_kwargs['primary_metric'] = primary_metric
    if n_jobs != -1:
        _lotus_kwargs['n_jobs'] = n_jobs
    if q_tol != 0.001:
        _lotus_kwargs['q_tol'] = q_tol
    if louvain_time_limit != 2000:
        _lotus_kwargs['louvain_time_limit'] = louvain_time_limit
    if nn_method != 'kdtree':
        _lotus_kwargs['nn_method'] = nn_method
    if partition_type is not None:
        _lotus_kwargs['partition_type'] = partition_type
    if resolution_parameter != 1:
        _lotus_kwargs['resolution_parameter'] = resolution_parameter
    if n_iterations != -1:
        _lotus_kwargs['n_iterations'] = n_iterations
    if use_weights != True:
        _lotus_kwargs['use_weights'] = use_weights
    if seed is not None:
        _lotus_kwargs['seed'] = seed
    if copy != False:
        _lotus_kwargs['copy'] = copy
    _lotus_kwargs.update(kargs)
    return _orig_module.phenograph(data, clustering_algo, **_lotus_kwargs)

def sam(adata: 'AnnData' = None, *, max_iter: 'int' = 10, num_norm_avg: 'int' = 50, k: 'int' = 20, distance: 'str' = 'correlation', standardization: "Literal['Normalizer', 'StandardScaler', 'None']" = 'StandardScaler', weight_pcs: 'bool' = False, sparse_pca: 'bool' = False, n_pcs: 'int | None' = 150, n_genes: 'int | None' = 3000, projection: "Literal['umap', 'tsne', 'None']" = 'umap', inplace: 'bool' = True, verbose: 'bool' = True, **_lotus_extras) -> 'SAM | tuple[SAM, AnnData]':
    _lotus_kwargs = {}
    if max_iter != 10:
        _lotus_kwargs['max_iter'] = max_iter
    if num_norm_avg != 50:
        _lotus_kwargs['num_norm_avg'] = num_norm_avg
    if k != 20:
        _lotus_kwargs['k'] = k
    if distance != 'correlation':
        _lotus_kwargs['distance'] = distance
    if standardization != 'StandardScaler':
        _lotus_kwargs['standardization'] = standardization
    if weight_pcs != False:
        _lotus_kwargs['weight_pcs'] = weight_pcs
    if sparse_pca != False:
        _lotus_kwargs['sparse_pca'] = sparse_pca
    if n_pcs != 150:
        _lotus_kwargs['n_pcs'] = n_pcs
    if n_genes != 3000:
        _lotus_kwargs['n_genes'] = n_genes
    if projection != 'umap':
        _lotus_kwargs['projection'] = projection
    if inplace != True:
        _lotus_kwargs['inplace'] = inplace
    if verbose != True:
        _lotus_kwargs['verbose'] = verbose
    _lotus_call_args = []
    if adata is not None:
        _lotus_call_args.append(adata)
    return _orig_module.sam(*_lotus_call_args, **_lotus_kwargs, **_lotus_extras)

def sandbag(adata: 'AnnData' = None, annotation: 'Mapping[str, Genes] | None' = None, *, fraction: 'float' = 0.65, filter_genes: 'Genes | None' = None, filter_samples: 'Genes | None' = None, **_lotus_extras) -> 'dict[str, list[tuple[str, str]]]':
    _lotus_kwargs = {}
    if fraction != 0.65:
        _lotus_kwargs['fraction'] = fraction
    if filter_genes is not None:
        _lotus_kwargs['filter_genes'] = filter_genes
    if filter_samples is not None:
        _lotus_kwargs['filter_samples'] = filter_samples
    _lotus_call_args = []
    if adata is not None:
        _lotus_call_args.append(adata)
    _lotus_call_args.append(annotation)
    return _orig_module.sandbag(*_lotus_call_args, **_lotus_kwargs, **_lotus_extras)

def trimap(adata: 'AnnData' = None, n_components: 'int' = 2, *, n_inliers: 'int' = 10, n_outliers: 'int' = 5, n_random: 'int' = 5, metric: "Literal['angular', 'euclidean', 'hamming', 'manhattan']" = 'euclidean', weight_adj: 'float' = 500.0, lr: 'float' = 1000.0, n_iters: 'int' = 400, verbose: 'bool | int | None' = None, copy: 'bool' = False, **_lotus_extras) -> 'AnnData | None':
    _lotus_kwargs = {}
    if n_inliers != 10:
        _lotus_kwargs['n_inliers'] = n_inliers
    if n_outliers != 5:
        _lotus_kwargs['n_outliers'] = n_outliers
    if n_random != 5:
        _lotus_kwargs['n_random'] = n_random
    if metric != 'euclidean':
        _lotus_kwargs['metric'] = metric
    if weight_adj != 500.0:
        _lotus_kwargs['weight_adj'] = weight_adj
    if lr != 1000.0:
        _lotus_kwargs['lr'] = lr
    if n_iters != 400:
        _lotus_kwargs['n_iters'] = n_iters
    if verbose is not None:
        _lotus_kwargs['verbose'] = verbose
    if copy != False:
        _lotus_kwargs['copy'] = copy
    _lotus_call_args = []
    if adata is not None:
        _lotus_call_args.append(adata)
    _lotus_call_args.append(n_components)
    return _orig_module.trimap(*_lotus_call_args, **_lotus_kwargs, **_lotus_extras)

def wishbone(adata: 'AnnData', start_cell: 'str', *, branch: 'bool' = True, k: 'int' = 15, components: 'Iterable[int]' = (1, 2, 3), num_waypoints: 'int | Collection' = 250, **_lotus_extras):
    _lotus_kwargs = {}
    if branch != True:
        _lotus_kwargs['branch'] = branch
    if k != 15:
        _lotus_kwargs['k'] = k
    if components != (1, 2, 3):
        _lotus_kwargs['components'] = components
    if num_waypoints != 250:
        _lotus_kwargs['num_waypoints'] = num_waypoints
    _lotus_call_args = []
    _lotus_call_args.append(adata)
    _lotus_call_args.append(start_cell)
    return _orig_module.wishbone(*_lotus_call_args, **_lotus_kwargs, **_lotus_extras)

def __getattr__(name: str):
    try:
        return getattr(_orig_module, name)
    except AttributeError as exc:
        raise AttributeError(f"scanpy.external.tl has no attribute {name!r}") from exc

def __dir__():
    return sorted(set(__all__) | {name for name in dir(_orig_module) if not name.startswith('__')})
